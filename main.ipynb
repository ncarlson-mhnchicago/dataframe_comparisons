{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37720520-d63c-463a-a847-b32721f068ff",
   "metadata": {
    "collapsed": false,
    "name": "description"
   },
   "source": [
    "### Dataframe Comparisons in Snowflake\n",
    "\n",
    "A DataFrame is a fundamental data structure in data analysis and programming, used to organize data into a two-dimensional table with rows and columns, similar to a spreadsheet or a table in a relational database. \n",
    "\n",
    "Using the Pandas library, Python can work with data in a dataframe structure. The Pandas dataframe however, stores all the data in memory which is problamatic for large data sets.  Snowflake has addressed this with the following two options: Snowpark DataFrame API and Snowpark Pandas DataFrame API.\n",
    "\n",
    "This tutorial will demonstrate and compare the three dataframe types.\n",
    "1. Snowpark DataFrame\n",
    "    - https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/dataframe\n",
    "\n",
    "2. Snowpark Pandas DataFame (aka Modin)\n",
    "    - https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/modin/dataframe\n",
    "\n",
    "3. Pandas DataFrame\n",
    "    - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.core import Root\n",
    "import modin.pandas as spd  # Snowpark Pandas API\n",
    "import snowflake.snowpark.modin.plugin  # Required for Snowpark Pandas API to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "python",
    "name": "create_session"
   },
   "outputs": [],
   "source": [
    "# Create a snowpark session\n",
    "session = get_active_session()\n",
    "\n",
    "# Add a query tag to the session for troubleshooting and monitoring\n",
    "session.query_tag = {\n",
    "    \"origin\":\"sf_sit-is\", \n",
    "    \"name\":\"dataframe_comparisons\", \n",
    "    \"version\":{\"major\":1, \"minor\":0},\n",
    "    \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\", \"vignette\":\"snowpark_pandas\"}\n",
    "}\n",
    "\n",
    "# Set root\n",
    "root = Root(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "sql",
    "name": "set_ddl"
   },
   "outputs": [],
   "source": [
    "-- Set DDL\n",
    "\n",
    "-- Warehouses\n",
    "CREATE OR REPLACE WAREHOUSE TEST_WH WAREHOUSE_SIZE = XSMALL, AUTO_SUSPEND = 300, AUTO_RESUME= TRUE;\n",
    "USE WAREHOUSE TEST_WH;\n",
    "\n",
    "-- Databases\n",
    "CREATE OR ALTER DATABASE dataframe_comparisons;\n",
    "USE DATABASE dataframe_comparisons;\n",
    "\n",
    "-- Schemas\n",
    "CREATE OR ALTER SCHEMA DATA;\n",
    "USE SCHEMA DATA;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcb18b-0e35-43c1-ab2f-58dc03bf4a91",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "python",
    "name": "set_data_paths"
   },
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "\n",
    "# Raw\n",
    "raw_db = \"SNOWFLAKE_SAMPLE_DATA\"\n",
    "raw_schema = \"TPCH_SF1000\"\n",
    "raw_table = \"LINEITEM\"\n",
    "raw_data_path = f\"{raw_db}.{raw_schema}.{raw_table}\"\n",
    "\n",
    "# Stage\n",
    "stage_db = \"dataframe_comparisons\"\n",
    "stage_schema = \"DATA\"\n",
    "stage_data_path_small = f\"{stage_db}.{stage_schema}.lineitem_small\"\n",
    "stage_data_path_medium = f\"{stage_db}.{stage_schema}.lineitem_medium\"\n",
    "stage_data_path_large = f\"{stage_db}.{stage_schema}.lineitem_large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d657b0-21eb-44c6-9f6c-d986943ba6f6",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "sql",
    "name": "load_data"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE {{stage_data_path_small}} AS\n",
    "    SELECT *\n",
    "    FROM {{raw_data_path}}\n",
    "    LIMIT 1000;\n",
    "\n",
    "CREATE OR REPLACE TABLE {{stage_data_path_medium}} AS\n",
    "    SELECT *\n",
    "    FROM {{raw_data_path}}\n",
    "    LIMIT 100000;\n",
    "\n",
    "CREATE OR REPLACE TABLE {{stage_data_path_large}} AS\n",
    "    SELECT *\n",
    "    FROM {{raw_data_path}}\n",
    "    LIMIT 10000000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1a523-6669-4a95-9366-8a97950b0324",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_df_from_records"
   },
   "outputs": [],
   "source": [
    "def create_dataframe_from_records(name):\n",
    "    # This function creates a dataframe from a set of records\n",
    "\n",
    "    column_list = ['Number', 'Name']\n",
    "    record_list = [\n",
    "        (1, 'one'),\n",
    "        (2, 'two')\n",
    "]\n",
    "    if name == 'snowpark_df':\n",
    "        return session.create_dataframe(record_list, schema=column_list)\n",
    "    \n",
    "    elif name == 'snowpark_pandas_df':\n",
    "        return spd.DataFrame(record_list, columns=column_list)\n",
    "    \n",
    "    else:\n",
    "        return pd.DataFrame(record_list, columns=column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f4a60-0ea4-48c4-9301-643fe8deae63",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_df_from_table"
   },
   "outputs": [],
   "source": [
    "def create_dataframe_from_table(name, path):\n",
    "    # This function creates a dataframe from a table\n",
    "    \n",
    "    if name == 'snowpark_df':\n",
    "        return session.table(path)\n",
    "    \n",
    "    elif name == 'snowpark_pandas_df':\n",
    "        return spd.read_snowflake(path)\n",
    "    \n",
    "    else:\n",
    "        # Note: This can't be done directly from within Snowflake\n",
    "        \n",
    "        # Option 1: Locally\n",
    "        # sql = \"SELECT * FROM db.schema.table\"\n",
    "        # cnxn = # make local connection to database\n",
    "        # pd.read_sql(sql,cnxn\n",
    "        \n",
    "        # Option 2: Using conversion (Note: use case for this is limited - think Matplotlib)\n",
    "        snowpark_df = session.table(path)\n",
    "        return snowpark_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87170a60-d640-4a2b-a203-eab3277f3159",
   "metadata": {
    "language": "python",
    "name": "display_df"
   },
   "outputs": [],
   "source": [
    "def display_dataframe(name, df):\n",
    "    \n",
    "    if name == 'snowpark_df':\n",
    "        df.first(10)\n",
    "    \n",
    "    elif name == 'snowpark_pandas_df':\n",
    "        df.head(10)\n",
    "    \n",
    "    else:\n",
    "        df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0302dfd-8407-4f7a-bff9-c823a06b859c",
   "metadata": {
    "language": "python",
    "name": "convert_df"
   },
   "outputs": [],
   "source": [
    "def convert_to_snowpark(name, df):\n",
    "    if name == 'snowpark_df':\n",
    "        new_df = df    \n",
    "    elif name == 'snowpark_pandas_df':\n",
    "        new_df = df.to_snowpark()\n",
    "    else:\n",
    "        new_df = session.create_dataframe(df)\n",
    "\n",
    "def convert_to_snowpark_pandas(name, df):\n",
    "    if name == 'snowpark_df':\n",
    "        new_df = df.to_snowpark_pandas()\n",
    "    elif name == 'snowpark_pandas_df':\n",
    "        new_df = df \n",
    "    else:\n",
    "        new_df = session.create_dataframe(df) # to snowpark first\n",
    "        new_df = new_df.to_snowpark_pandas() # then to snowpark_pandas\n",
    "\n",
    "def convert_to_pandas(name, df):\n",
    "    if name == 'snowpark_df':\n",
    "        new_df = df.to_pandas()\n",
    "    elif name == 'snowpark_pandas_df':\n",
    "        new_df = df.to_pandas()\n",
    "    else:\n",
    "        new_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1b807-9322-4d92-9624-0de293e61fb0",
   "metadata": {
    "language": "python",
    "name": "run_comparisons_test"
   },
   "outputs": [],
   "source": [
    "time_columns = ['job', 'df', 'table_size', 'execution_time']\n",
    "time_records = []\n",
    "\n",
    "name_list = ['snowpark_df', 'snowpark_pandas_df', 'pandas_df']\n",
    "table_list = [\n",
    "    {'size': 'small', 'path': stage_data_path_small},\n",
    "    {'size': 'medium', 'path': stage_data_path_medium},\n",
    "    {'size': 'large', 'path':stage_data_path_large}\n",
    "]\n",
    "df_dict = {}\n",
    "\n",
    "for indx, name in enumerate(name_list):\n",
    "    # create_dataframe_from_records\n",
    "    start = datetime.now()\n",
    "    create_dataframe_from_records(name)\n",
    "    stop = datetime.now()\n",
    "    execution_time = str(stop - start)\n",
    "    df_name = f\"{indx} {name}\"\n",
    "    job_name = '0 create_dataframe_from_records'\n",
    "    time_records.append((job_name, df_name, 'n/a', execution_time))\n",
    "    \n",
    "    for table in table_list:   \n",
    "        # create_dataframe_from_table\n",
    "        start = datetime.now()\n",
    "        df = create_dataframe_from_table(name, table['path'])\n",
    "        df_dict[name] = df\n",
    "        stop = datetime.now()\n",
    "        execution_time = str(stop - start)\n",
    "        df_name = f\"{indx} {name}\"\n",
    "        job_name = '1 create_dataframe_from_table'\n",
    "        time_records.append((job_name, df_name, table['size'], execution_time))\n",
    "\n",
    "        # display_dataframe\n",
    "        start = datetime.now()\n",
    "        display_dataframe(name, df)\n",
    "        stop = datetime.now()\n",
    "        execution_time = str(stop - start)\n",
    "        df_name = f\"{indx} {name}\"\n",
    "        job_name = '2 display_dataframe'\n",
    "        time_records.append((job_name, df_name, table['size'], execution_time))\n",
    "        \n",
    "        # convert_dataframes\n",
    "        start = datetime.now()\n",
    "        try:\n",
    "            convert_to_snowpark(name, df)\n",
    "        except Exception as e:\n",
    "            print(f\"convert_to_snowpark {name} error: {e}\")\n",
    "        stop = datetime.now()\n",
    "        execution_time = str(stop - start)\n",
    "        df_name = f\"{indx} {name}\"\n",
    "        job_name = '3a convert_to_snowpark'\n",
    "        time_records.append((job_name, df_name, table['size'], execution_time))\n",
    "\n",
    "        start = datetime.now()\n",
    "        try:\n",
    "            convert_to_snowpark_pandas(name, df)\n",
    "        except Exception as e:\n",
    "            print(f\"convert_to_snowpark_pandas {name} error: {e}\")\n",
    "        stop = datetime.now()\n",
    "        execution_time = str(stop - start)\n",
    "        df_name = f\"{indx} {name}\"\n",
    "        job_name = '3b convert_to_snowpark_pandas'\n",
    "        time_records.append((job_name, df_name, table['size'], execution_time))\n",
    "\n",
    "        start = datetime.now()\n",
    "        try:\n",
    "            convert_to_pandas(name, df)\n",
    "        except Exception as e:\n",
    "            print(f\"convert_to_pandas {name} error: {e}\")\n",
    "        stop = datetime.now()\n",
    "        execution_time = str(stop - start)\n",
    "        df_name = f\"{indx} {name}\"\n",
    "        job_name = '3c convert_to_pandas'\n",
    "        time_records.append((job_name, df_name, table['size'], execution_time))\n",
    "\n",
    "# Display comparisons\n",
    "compare_df = pd.DataFrame(time_records, columns=time_columns)\n",
    "compare_df.sort_values(['job', 'df', 'table_size'],  ascending=[True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea8fad",
   "metadata": {
    "vscode": {
     "languageId": "snowflake-sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Teardown\n",
    "\n",
    "DROP DATABASE dataframe_comparisons;\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "ncarlson@mhnchicago.org",
   "authorId": "2138240225000",
   "authorName": "NCARLSON",
   "lastEditTime": 1750191677735,
   "notebookId": "elcpfyemkejspyhvenxn",
   "sessionId": "93aa4206-6aea-4f15-8cca-7b4cb72c1175"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
